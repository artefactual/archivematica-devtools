#!/usr/bin/env python2
# -*- coding: utf-8 -*-

# This file is part of the Archivematica development tools.
#
# Copyright 2010-2016 Artefactual Systems Inc. <http://artefactual.com>
#
# Archivematica is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Archivematica is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Archivematica.  If not, see <http://www.gnu.org/licenses/>.

from __future__ import print_function

import argparse
import shutil
import os
import re
import subprocess
import sys
import time
import tempfile

import django
from lxml import etree

sys.path.append("/usr/lib/archivematica/archivematicaCommon")
import elasticSearchFunctions

NSMAP = {
    'dc': 'http://purl.org/dc/terms/',
    'm': 'http://www.loc.gov/METS/',
    'x': 'http://www.w3.org/1999/xlink',
}
django.setup()

def extract_file(archive_path, destination_dir, relative_path):
    """ Extracts `relative_path` from `archive_path` into `destination_dir`. """
    if os.path.isdir(archive_path):
        output_path = os.path.join(destination_dir, os.path.basename(relative_path))
        shutil.copy(os.path.join(archive_path, relative_path), output_path)
    else:
        command_data = [
            'unar',
            '-force-overwrite',
            '-o', destination_dir,
            archive_path,
            relative_path,
        ]

        print('Command to run:', command_data)
        subprocess.call(command_data)
        output_path = os.path.join(destination_dir, relative_path)

    return output_path

def get_aips_in_aic(mets_root, archive_path, temp_dir):
    """ Returns the number of AIPs in the AIC, extracted from AIC METS file. """
    # Find name of AIC METS file
    try:
        # aic_mets_filename includes metadata/
        aic_mets_filename = mets_root.find("m:fileSec/m:fileGrp[@USE='metadata']/m:file/m:FLocat", namespaces=NSMAP).get('{'+NSMAP['x']+'}href')
        aip_dirname = mets_root.find("m:structMap/m:div", namespaces=NSMAP).get('LABEL')
    except Exception:
        # Catch any parsing errors
        return None

    # Extract AIC METS file
    aic_mets_path = extract_file(archive_path=archive_path,
        destination_dir=temp_dir,
        relative_path=os.path.join(aip_dirname, 'data', aic_mets_filename))

    # Parse for number of AIPs
    aic_root = etree.parse(aic_mets_path)
    extent = aic_root.find("m:dmdSec/m:mdWrap/m:xmlData/dc:dublincore/dc:extent", namespaces=NSMAP)
    try:
        aips_in_aic = re.search("\d+", extent.text).group()
    except AttributeError:
        # Probably because extent was None
        # Or the search returned None
        return None

    return aips_in_aic


def processAIPThenDeleteMETSFile(path, temp_dir, es_client, delete_existing_data=False):
    archive_file = os.path.basename(path)

    # Regex match the UUID - AIP might end with .7z, .tar.bz2, or something else
    match = re.search(r"[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}", archive_file)
    if match is not None:
        aip_uuid = match.group()
    else:
        return -1

    print('Processing AIP', aip_uuid)

    if delete_existing_data is True:
        print('Deleting AIP', aip_uuid, 'from aips/aip and aips/aipfile.')
        try:
            elasticSearchFunctions.delete_aip(es_client, aip_uuid)
        except TypeError:
            elasticSearchFunctions.delete_aip(aip_uuid)  # AM 1.5
        try:
            elasticSearchFunctions.delete_aip_files(es_client, aip_uuid)
        except AttributeError:
            elasticSearchFunctions.connect_and_delete_aip_files(aip_uuid)  # AM 1.5

    # AIP filenames are <name>-<uuid><extension>
    # Index of match end is right before the extension
    subdir = archive_file[:match.end()]
    aip_name = subdir[:-37]
    mets_file = "METS." + aip_uuid + ".xml"
    mets_file_relative_path = os.path.join("data", mets_file)
    if os.path.isfile(path):
        mets_file_relative_path = os.path.join(subdir, mets_file_relative_path)
    path_to_mets = extract_file(archive_path=path,
        destination_dir=temp_dir, relative_path=mets_file_relative_path)

    # If AIC, need to extract number of AIPs in AIC to index as well
    aips_in_aic = None
    root = etree.parse(path_to_mets)
    try:
        aip_type = root.find("m:dmdSec/m:mdWrap/m:xmlData/dc:dublincore/dc:type", namespaces=NSMAP).text
    except AttributeError:
        pass
    else:
        if aip_type == "Archival Information Collection":
            aips_in_aic = get_aips_in_aic(root, path, temp_dir)

    try:
        elasticSearchFunctions.index_aip(
            client=es_client,
            uuid=aip_uuid,
            name=aip_name,
            filePath=path,
            pathToMETS=path_to_mets,
            aips_in_aic=aips_in_aic,
            identifiers=[],  # TODO get these
        )
    except AttributeError:  # AM 1.5
        elasticSearchFunctions.connect_and_index_aip(
            uuid=aip_uuid,
            name=aip_name,
            filePath=path,
            pathToMETS=path_to_mets,
            aips_in_aic=aips_in_aic,
            identifiers=[],  # TODO get these
        )
    try:
        elasticSearchFunctions.index_mets_file_metadata(
            client=es_client,
            uuid=aip_uuid,
            metsFilePath=path_to_mets,
            index='aips',
            type_='aipfile',
            sipName=aip_name,
            identifiers=[],  # TODO get these
        )
    except TypeError:  # AM 1.5
        elasticSearchFunctions.index_mets_file_metadata(
            conn=es_client,
            uuid=aip_uuid,
            metsFilePath=path_to_mets,
            index='aips',
            type='aipfile',
            sipName=aip_name,
            identifiers=[],  # TODO get these
        )


def main():
    parser = argparse.ArgumentParser(description='Recreate the ElasticSearch AIP index from AIPS accessible locally')

    parser.add_argument('-d', '--delete', action='store_true',
        help='Delete AIP-related ElasticSearch data before indexing AIP data')
    parser.add_argument('--delete-all', action='store_true',
        help='Delete all AIP information in the index before starting. This will remove ElasticSearch entries for AIPS that do not exist in the provided directory.')
    parser.add_argument('-u', '--uuid', action='store', default='',
        help='Specify a single AIP by UUID to process')
    parser.add_argument('rootdir', help='Path to the directory containing the AIPs', metavar='PATH')

    args = parser.parse_args()

    # Check root directory exists
    if not os.path.isdir(args.rootdir):
        print("AIP store location doesn't exist.")
        sys.exit(1)

    # Verify ES is accessible
    try:
        elasticSearchFunctions.setup(hosts='localhost')
        es_client = elasticSearchFunctions.get_client()
    except AttributeError:
        es_client = elasticSearchFunctions.Elasticsearch(hosts=elasticSearchFunctions.getElasticsearchServerHostAndPort())  # AM 1.5

    try:
        es_client.info()
    except Exception:
        print("Error: Elasticsearch may not be running.")
        sys.exit(1)

    # Delete existing data also clears AIPS not found in the provided directory
    if args.delete_all:
        print('Deleting all AIPs in the AIP index')
        time.sleep(3)  # Time for the user to panic and kill the process
        es_client.indices.delete('aips', ignore=404)
        try:
            elasticSearchFunctions.create_indexes_if_needed(es_client)
        except AttributeError:
            elasticSearchFunctions.check_server_status_and_create_indexes_if_needed()  # AM 1.5

    if not args.uuid:
        print("Rebuilding AIPS index from AIPS in", args.rootdir)
    else:
        print("Rebuilding AIP UUID", args.uuid)

    temp_dir = tempfile.mkdtemp()
    count = 0
    name_regex = r"-[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}"
    dir_regex = r"-[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$"

    for root, directories, files in os.walk(args.rootdir):
        # Uncompressed AIPs
        for directory in directories:
            # Check if dir name matches AIP name format
            match = re.search(dir_regex, directory)
            if not match:
                continue
            # If running on a single AIP, skip all others
            if args.uuid and args.uuid.lower() not in directory.lower():
                continue
            count += 1
            processAIPThenDeleteMETSFile(
                path=os.path.join(root, directory),
                temp_dir=temp_dir,
                es_client=es_client,
                delete_existing_data=args.delete,
            )
            # Don't recurse into this directory
            directories = directories.remove(directory)

        # Compressed AIPs
        for filename in files:
            # Check if filename matches AIP name format
            match = re.search(name_regex, filename)
            if not match:
                continue
            # If running on a single AIP, skip all others
            if args.uuid and args.uuid.lower() not in filename.lower():
                continue
            count += 1
            processAIPThenDeleteMETSFile(
                path=os.path.join(root, filename),
                temp_dir=temp_dir,
                es_client=es_client,
                delete_existing_data=args.delete,
            )

    print("Cleaning up")

    shutil.rmtree(temp_dir)

    print("Indexing complete. Indexed", count, "AIPs")


if __name__ == '__main__':
    main()
